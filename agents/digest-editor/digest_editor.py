#!/usr/bin/env python3
"""
RSS æ–‡æ‘˜ç¼–è¾‘å™¨ Agent

è‡ªåŠ¨æŠ“å– RSS æ›´æ–°ï¼Œç”Ÿæˆç²¾é€‰æ‘˜è¦ã€‚
"""

import httpx
from datetime import datetime, timedelta
from typing import List, Dict, Any
import json


RSS_API_BASE = "http://localhost:8000"


def ingest_feeds() -> Dict[str, Any]:
    """æŠ“å–æœ€æ–° RSS å†…å®¹"""
    r = httpx.post(f"{RSS_API_BASE}/ingest")
    return r.json()


def get_sources_with_unread() -> List[Dict[str, Any]]:
    """è·å–æœ‰æœªè¯»å†…å®¹çš„è®¢é˜…æº"""
    r = httpx.get(f"{RSS_API_BASE}/sources/meta")
    return [s for s in r.json() if s.get('unread_count', 0) > 0]


def get_digest(date: str = None) -> Dict[str, Any]:
    """è·å–æŒ‡å®šæ—¥æœŸçš„æ—¥æŠ¥"""
    date = date or datetime.utcnow().strftime("%Y-%m-%d")
    r = httpx.get(f"{RSS_API_BASE}/digest", params={"date": date})
    return r.json()


def generate_summary(entries: List[Dict], max_entries: int = 10) -> List[Dict[str, str]]:
    """ç”Ÿæˆç²¾é€‰æ‘˜è¦"""
    summaries = []
    
    for i, entry in enumerate(entries[:max_entries]):
        summary = {
            "index": i + 1,
            "title": entry.get("title", "æ— æ ‡é¢˜"),
            "source": entry.get("source_title", "æœªçŸ¥æ¥æº"),
            "summary": clean_summary(entry.get("summary", "")),
            "link": entry.get("link", "")
        }
        summaries.append(summary)
    
    return summaries


def clean_summary(text: str, max_words: int = 100) -> str:
    """æ¸…ç†å’Œæˆªå–æ‘˜è¦"""
    # ç§»é™¤ HTML æ ‡ç­¾
    import re
    text = re.sub(r'<[^>]+>', '', text)
    # è§£ç  HTML å®ä½“
    text = text.replace('&#8217;', "'").replace('&#8230;', '...')
    text = text.replace('&nbsp;', ' ').replace('&lt;', '<').replace('&gt;', '>')
    # æˆªå–æŒ‡å®šè¯æ•°
    words = text.split()[:max_words]
    return ' '.join(words) + ('...' if len(text.split()) > max_words else '')


def format_digest_report(summary_data: Dict) -> str:
    """æ ¼å¼åŒ–æ—¥æŠ¥æŠ¥å‘Š"""
    entries = summary_data.get('entries', [])
    categories = summary_data.get('categories', {})
    
    if not entries:
        return "ğŸ“­ ä»Šæ—¥æš‚æ— æ–°å†…å®¹æ›´æ–°"
    
    report = f"## ğŸ“° RSS æ–‡æ‘˜æ—¥æŠ¥ - {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}\n\n"
    report += f"**æ¥æº**: {len(entries)} ä¸ªè®¢é˜…æº\n\n"
    report += "---\n\n"
    
    # æŒ‰åˆ†ç±»å±•ç¤º
    for category, cat_entries in categories.items():
        report += f"### ğŸ“ {category}\n\n"
        for entry in cat_entries[:5]:  # æ¯ç±»æœ€å¤š5æ¡
            report += f"**{entry['title'][:60]}...**\n\n"
            report += f"> {clean_summary(entry.get('summary', ''), 50)}\n\n"
        report += "\n"
    
    # ç²¾é€‰æ‘˜è¦
    report += "### âœ¨ ç²¾é€‰æ‘˜è¦\n\n"
    selected = generate_summary(entries, 8)
    for item in selected:
        report += f"**{item['index']}. {item['title'][:50]}...**\n\n"
        report += f"> æ¥æº: {item['source']}\n\n"
        report += f">{item['summary']}\n\n"
    
    report += f"\nğŸ’¡ å…±æ”¶å½• {len(entries)} æ¡æ›´æ–°ï¼Œæ¥æº: {', '.join(set(e.get('source_title', '') for e in entries))}"
    
    return report


def run():
    """æ‰§è¡Œæ–‡æ‘˜ç”Ÿæˆæµç¨‹"""
    print("ğŸ“¥ å¼€å§‹æŠ“å– RSS æ›´æ–°...")
    
    # 1. æŠ“å–æ–°å†…å®¹
    ingest_result = ingest_feeds()
    print(f"âœ… æŠ“å–å®Œæˆ: æ–°å¢ {ingest_result.get('inserted', 0)} æ¡")
    
    # 2. è·å–æœªè¯»æº
    unread_sources = get_sources_with_unread()
    print(f"ğŸ“š æœ‰æ›´æ–°çš„è®¢é˜…æº: {len(unread_sources)}")
    
    # 3. è·å–æ—¥æŠ¥æ•°æ®
    today = datetime.utcnow().strftime("%Y-%m-%d")
    digest = get_digest(today)
    
    # 4. ç”ŸæˆæŠ¥å‘Š
    report = format_digest_report(digest)
    print("\n" + "="*50)
    print(report)
    print("="*50)
    
    return report


if __name__ == "__main__":
    run()
